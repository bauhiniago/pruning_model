{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCkPHee-alKM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "cvrknnPsaqaM"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7IGLmaw5DjA"
   },
   "source": [
    "## 关于如何使用模型压缩工具\n",
    "代码关于模型权重剪枝，tensorflow模型的优化工具\n",
    "\n",
    "权重剪枝的作用：1、模型压缩；2、运行加速。\n",
    "\n",
    "关于keras的权重剪枝api，可以在训练过程中对模型进行剪枝，或对预训练模型进行剪枝。\n",
    "\n",
    "这个api同样可以在TensorFlow Lite场景下使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8qFbkru8FKu"
   },
   "source": [
    "## 安装环境 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q8zIQsT9mUTw"
   },
   "source": [
    "使用剪枝  `tensorflow-model-optimization` 包的API.详细见 [TensorFlow model optimization repo](https://github.com/tensorflow/model-optimization) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "id": "Pn836LSTNSHA",
    "outputId": "96b2aab3-ca92-4ee4-bf47-9d71e95c96a4"
   },
   "outputs": [],
   "source": [
    "# ! pip uninstall -y tensorflow\n",
    "# ! pip uninstall -y tf-nightly\n",
    "# ! pip install -U tensorflow-gpu==1.14.0\n",
    "\n",
    "# ! pip install tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ykjgo4UNXmD"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mydXeQlDNbnR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda2\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBYltugp-MdR"
   },
   "source": [
    "## 加载mnist数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "P_MJqxz5z2dh",
    "outputId": "cf2d0433-6fc3-4ec9-a56d-46416be49615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "  input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "  input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmdnYKPK--5L"
   },
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "uLg0SGdYp2Q6",
    "outputId": "0811a622-9d22-4e2c-a9b7-c3e77cd1e454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,762\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l = tf.keras.layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    l.Conv2D(\n",
    "        32, 5, padding='same', activation='relu', input_shape=input_shape),\n",
    "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    l.BatchNormalization(),\n",
    "    l.Conv2D(64, 5, padding='same', activation='relu'),\n",
    "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    l.Flatten(),\n",
    "    l.Dense(1024, activation='relu'),\n",
    "    l.Dropout(0.4),\n",
    "    l.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dHynoso_xXF"
   },
   "source": [
    "### 训练模型， accuracy >99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "id": "A7c-fsQpTzOr",
    "outputId": "8526e351-6ec5-49a3-e7f3-3e96ebe180f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 78s 1ms/sample - loss: 0.2900 - acc: 0.9442 - val_loss: 0.0854 - val_acc: 0.9850\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0458 - acc: 0.9856 - val_loss: 0.0276 - val_acc: 0.9909\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0410 - val_acc: 0.9867\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0239 - acc: 0.9923 - val_loss: 0.0343 - val_acc: 0.9897\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0220 - acc: 0.9926 - val_loss: 0.0254 - val_acc: 0.9930\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 74s 1ms/sample - loss: 0.0188 - acc: 0.9940 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0294 - val_acc: 0.9921\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0146 - acc: 0.9952 - val_loss: 0.0276 - val_acc: 0.9921\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 74s 1ms/sample - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0321 - val_acc: 0.9913\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.0155 - acc: 0.9955 - val_loss: 0.0633 - val_acc: 0.9852\n",
      "Test loss: 0.0632856609915988\n",
      "Test accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "logdir=\"./tensorboard_logs/logs\"\n",
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=0)]\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLgMavDVCde5"
   },
   "source": [
    "### 保存原始模型，以方便后续对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8E6U7GUIx5r9",
    "outputId": "315c8972-014e-4052-e703-c814c902d23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to:  C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpvnea6y58.h5\n"
     ]
    }
   ],
   "source": [
    "# 在临时目录下保存模型文件\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWiQbobKC0NZ"
   },
   "source": [
    "## 训练一个剪枝模型\n",
    "\n",
    "可以使用 `prune_low_magnitude()` API 对模型进行剪枝. 这个api可以应用与单个网络层或者是整个网络模型。\n",
    "\n",
    "可以设立参数配置：将以75%的稀疏性为目标，从步骤2000开始，每100步（也称为epoch）修剪一次权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfJ6Tm3KXMFY"
   },
   "source": [
    "### 建立基于单个网络层剪枝的模型\n",
    "In this example, we show how to use the API at the level of layers, and build a pruned MNIST solver model.\n",
    "\n",
    "In this case, the `prune_low_magnitude(`) \n",
    "receives as parameter the Keras layer whose weights we want pruned.\n",
    "\n",
    "This function requires a pruning params which configures the pruning algorithm during training. Please refer to our github page for detailed documentation. The parameter used here means:\n",
    "\n",
    "\n",
    "1.   **Sparsity.** PolynomialDecay is used across the whole training process. We start at the sparsity level 50% and gradually train the model to reach 90% sparsity. X% sparsity means that X% of the weight tensor is going to be pruned away.\n",
    "2.   **Schedule**. Connections are pruned starting from step 2000 to the end of training, and runs every 100 steps. The reasoning behind this is that we want to train the model without pruning for a few epochs to reach a certain accuracy, to aid convergence. Furthermore, we give the model some time to recover after each pruning step, so pruning does not happen on every step. We set the pruning frequency to 100.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "Ip8qCtSlU3TQ",
    "outputId": "6c59898f-7d27-4d6d-82c4-dd4a5c8d8cdc"
   },
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity import keras as sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tA9rnRUrebTE"
   },
   "source": [
    "四个重要的参数： begin_sparsity, final_sparsity, begin_step and end_step。其中，end_step参数需要根据训练数据的数量、batch size和pochs来确定。\n",
    "\n",
    "下面定义这四个重要参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rrs-xoB2cSSQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End step: 5628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "epochs = 12\n",
    "num_train_samples = x_train.shape[0]\n",
    "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
    "print('End step: ' + str(end_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Shz-r2RiqFca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_schedule.py:240: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d_2 (None, 28, 28, 32)        1634      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_3 (None, 14, 14, 64)        102466    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_2  (None, 1024)              6423554   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_3  (None, 10)                20492     \n",
      "=================================================================\n",
      "Total params: 6,548,274\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 3,273,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=2000,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=100)\n",
    "}\n",
    "\n",
    "pruned_model = tf.keras.Sequential([\n",
    "    sparsity.prune_low_magnitude(\n",
    "        l.Conv2D(32, 5, padding='same', activation='relu'),\n",
    "        input_shape=input_shape,\n",
    "        **pruning_params),\n",
    "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    l.BatchNormalization(),\n",
    "    sparsity.prune_low_magnitude(\n",
    "        l.Conv2D(64, 5, padding='same', activation='relu'), **pruning_params),\n",
    "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    l.Flatten(),\n",
    "    sparsity.prune_low_magnitude(l.Dense(1024, activation='relu'),\n",
    "                                 **pruning_params),\n",
    "    l.Dropout(0.4),\n",
    "    sparsity.prune_low_magnitude(l.Dense(num_classes, activation='softmax'),\n",
    "                                 **pruning_params)\n",
    "])\n",
    "\n",
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2166laKE_N6"
   },
   "source": [
    "### 训练剪枝模型\n",
    "\n",
    "Start pruning from step 2000 when accuracy >98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGoOTwQRzEP4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2545 - acc: 0.9423INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 78s 1ms/sample - loss: 0.2542 - acc: 0.9423 - val_loss: 0.1370 - val_acc: 0.9868\n",
      "Epoch 2/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9863INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 77s 1ms/sample - loss: 0.0438 - acc: 0.9863 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "Epoch 3/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9911INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0300 - acc: 0.9911 - val_loss: 0.0362 - val_acc: 0.9881\n",
      "Epoch 4/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9920INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 78s 1ms/sample - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0240 - val_acc: 0.9918\n",
      "Epoch 5/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9941INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0206 - val_acc: 0.9934\n",
      "Epoch 6/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9949- ETA: 0s - loss: 0.0159 - acc: 0.99INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 87s 1ms/sample - loss: 0.0159 - acc: 0.9949 - val_loss: 0.0239 - val_acc: 0.9928\n",
      "Epoch 7/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9957INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0251 - val_acc: 0.9916\n",
      "Epoch 8/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9954INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 87s 1ms/sample - loss: 0.0141 - acc: 0.9955 - val_loss: 0.0222 - val_acc: 0.9925\n",
      "Epoch 9/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9954INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 80s 1ms/sample - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Epoch 10/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9956INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 86s 1ms/sample - loss: 0.0128 - acc: 0.9956 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Test loss: 0.02419760778253367\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "logdir=\"./tensorboard_logs/pruning_training_logs\"\n",
    "pruned_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
    "# step. Also add a callback to add pruning summaries to tensorboard\n",
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]\n",
    "\n",
    "pruned_model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = pruned_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Nzrm5pN1viP"
   },
   "source": [
    "### 保存并加载剪枝模型\n",
    "\n",
    "加载完剪枝模型后，再训练两个epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rd8G7srV2dcI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpr0fljmte.h5\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9966INFO:tensorflow:Summary name prune_low_magnitude_dense_2_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2_1/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0264 - val_acc: 0.9917\n",
      "Epoch 2/2\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9978INFO:tensorflow:Summary name prune_low_magnitude_dense_2_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_2_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2_1/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 92s 2ms/sample - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0266 - val_acc: 0.9916\n",
      "Test loss: 0.02660627384511172\n",
      "Test accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "_, checkpoint_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', checkpoint_file)\n",
    "# saved_model() sets include_optimizer to True by default. Spelling it out here\n",
    "# to highlight.\n",
    "tf.keras.models.save_model(pruned_model, checkpoint_file, include_optimizer=True)\n",
    "\n",
    "with sparsity.prune_scope():\n",
    "  restored_model = tf.keras.models.load_model(checkpoint_file)\n",
    "\n",
    "restored_model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=2,\n",
    "                   verbose=1,\n",
    "                   callbacks=callbacks,\n",
    "                   validation_data=(x_test, y_test))\n",
    "\n",
    "score = restored_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vV7pZrW5TQh"
   },
   "source": [
    "需要注意的是\n",
    "\n",
    "*  保存模型要将参数 include_optimizer 设置为 True. \n",
    "*   加载模型的时候，需要使用 prune_scope() 进行反序列化\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMTFhyc0vAA3"
   },
   "source": [
    "### 使用剪枝模型之前，需要从剪枝模型中去除剪枝模块\n",
    "\n",
    "使用strip_pruning` API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyCjjpUjvImz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,762\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = sparsity.strip_pruning(pruned_model)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B63tViKp_qLK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpocutxj12.h5\n"
     ]
    }
   ],
   "source": [
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', pruned_keras_file)\n",
    "\n",
    "# 不需要保存优化器模块\n",
    "tf.keras.models.save_model(final_model, pruned_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhXHuBAGOBvY"
   },
   "source": [
    "### Compare the size of the unpruned vs. pruned model after compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hk4DoZTIy2uU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unpruned model before compression: 12.52 Mb\n",
      "Size of the unpruned model after compression: 11.59 Mb\n",
      "Size of the pruned model before compression: 12.52 Mb\n",
      "Size of the pruned model after compression: 2.51 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip1 = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(keras_file)\n",
    "print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "      (os.path.getsize(keras_file) / float(2**20)))\n",
    "print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "      (os.path.getsize(zip1) / float(2**20)))\n",
    "\n",
    "_, zip2 = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip2, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(pruned_keras_file)\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" % \n",
    "      (os.path.getsize(pruned_keras_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" % \n",
    "      (os.path.getsize(zip2) / float(2**20)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dayb_w_GqWs_"
   },
   "source": [
    "### 对预训练模型进行剪枝\n",
    "\n",
    "`prune_low_magnitude` 函数同样可以对整个keras模型进行剪枝。这时候，将是对所有网络层进行剪枝。\n",
    "\n",
    "注意：\n",
    "1、对于无法剪枝的官方网络层不起作用剪枝参数将被忽略,但对于未知的层（非官方网络层）的使用会报错。\n",
    "2、对于不确定剪枝方案的网络层可以指定\"un-pruned\"参数。\n",
    "\n",
    "对于预训练模型的剪枝需要进行 re-compile 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-W7Sj8fZjeb"
   },
   "source": [
    "Before we move forward with the example, lets address the common use case where you may already have a serialized pre-trained Keras model, which you would like to apply weight pruning on. We will take the original MNIST model trained previously to show how this works. In this case, you start by loading the model into memory like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJm1SJxfqy2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load the serialized model\n",
    "loaded_model = tf.keras.models.load_model(keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etYrWnrSMpB5"
   },
   "source": [
    "对预训练模型进行剪枝，需要从step 0开始.由于预训练模型已经达到我们想要的准确度，所以这里我们可以直接对模型剪枝，设置 begin_step = 0 训练4个 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CabnOldzrSN2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d ( (None, 28, 28, 32)        1634      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 14, 14, 32)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 14, 14, 32)        129       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 14, 14, 64)        102466    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 7, 7, 64)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 3136)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 1024)              6423554   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout  (None, 1024)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 10)                20492     \n",
      "=================================================================\n",
      "Total params: 6,548,279\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 3,273,581\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
    "print(end_step)\n",
    "\n",
    "new_pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=0,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=100)\n",
    "}\n",
    "\n",
    "new_pruned_model = sparsity.prune_low_magnitude(model, **new_pruning_params)\n",
    "new_pruned_model.summary()\n",
    "\n",
    "new_pruned_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"./tensorboard_logs/pruning_pretrained_logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36hymxokrnbw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9959INFO:tensorflow:Summary name prune_low_magnitude_dense/threshold:0/threshold is illegal; using prune_low_magnitude_dense/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense/mask:0/sparsity is illegal; using prune_low_magnitude_dense/mask_0/sparsity instead.\n",
      "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0283 - val_acc: 0.9916\n",
      "Epoch 2/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9947INFO:tensorflow:Summary name prune_low_magnitude_dense/threshold:0/threshold is illegal; using prune_low_magnitude_dense/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense/mask:0/sparsity is illegal; using prune_low_magnitude_dense/mask_0/sparsity instead.\n",
      "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0316 - val_acc: 0.9904\n",
      "Epoch 3/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9939INFO:tensorflow:Summary name prune_low_magnitude_dense/threshold:0/threshold is illegal; using prune_low_magnitude_dense/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense/mask:0/sparsity is illegal; using prune_low_magnitude_dense/mask_0/sparsity instead.\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0201 - acc: 0.9939 - val_loss: 0.0329 - val_acc: 0.9893\n",
      "Epoch 4/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9948INFO:tensorflow:Summary name prune_low_magnitude_dense/threshold:0/threshold is illegal; using prune_low_magnitude_dense/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense/mask:0/sparsity is illegal; using prune_low_magnitude_dense/mask_0/sparsity instead.\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0217 - val_acc: 0.9924\n",
      "Test loss: 0.021687601001961595\n",
      "Test accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
    "# step. Also add a callback to add pruning summaries to tensorboard\n",
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]\n",
    "\n",
    "new_pruned_model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = new_pruned_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0yphbuRarfT"
   },
   "source": [
    "### Export the pruned model for serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anFHUpCXrxMe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,762\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = sparsity.strip_pruning(pruned_model)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CmEtxHEso7g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpspcgd27o.h5\n"
     ]
    }
   ],
   "source": [
    "_, new_pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', new_pruned_keras_file)\n",
    "tf.keras.models.save_model(final_model, new_pruned_keras_file, \n",
    "                        include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YT8YqXAza3Tt"
   },
   "source": [
    "The model size after compression is the same as the one pruned layer-by-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtKANC0hs2RR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned model before compression: 12.52 Mb\n",
      "Size of the pruned model after compression: 2.51 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip3 = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip3, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(new_pruned_keras_file)\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(new_pruned_keras_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip3) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXrLGUPfIwvV"
   },
   "source": [
    "## 转化成 TensorFlow Lite\n",
    "\n",
    "转化需要使用 TFLiteConverter 的api:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1f9Eb2K0bcJG"
   },
   "source": [
    "### 使用TFLiteConverter转化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ctqfiix-H-x7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "INFO:tensorflow:Converted 12 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = './sparse_mnist.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(pruned_keras_file)\n",
    "tflite_model = converter.convert()\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdIiNnrPANcw"
   },
   "source": [
    "### 对比 TensorFlow Lite 模型和压缩文件的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYMSXAU1AUYI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the tflite model before compression: 12.49 Mb\n",
      "Size of the tflite model after compression: 2.42 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_tflite = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(tflite_model_file)\n",
    "print(\"Size of the tflite model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(tflite_model_file) / float(2**20)))\n",
    "print(\"Size of the tflite model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip_tflite) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBqUX1qopV1k"
   },
   "source": [
    "### 评估TensorFlow Lite 模型的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5AY-TuivmbP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 1000 images: 0.993000\n",
      "Accuracy after 2000 images: 0.991000\n",
      "Accuracy after 3000 images: 0.987333\n",
      "Accuracy after 4000 images: 0.989000\n",
      "Accuracy after 5000 images: 0.988800\n",
      "Accuracy after 6000 images: 0.990333\n",
      "Accuracy after 7000 images: 0.990714\n",
      "Accuracy after 8000 images: 0.991875\n",
      "Accuracy after 9000 images: 0.992556\n",
      "Accuracy after 10000 images: 0.992200\n",
      "0.9922\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "def eval_model(interpreter, x_test, y_test):\n",
    "  total_seen = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for img, label in zip(x_test, y_test):\n",
    "    inp = img.reshape((1, 28, 28, 1))\n",
    "    total_seen += 1\n",
    "    interpreter.set_tensor(input_index, inp)\n",
    "    interpreter.invoke()\n",
    "    predictions = interpreter.get_tensor(output_index)\n",
    "    if np.argmax(predictions) == np.argmax(label):\n",
    "      num_correct += 1\n",
    "\n",
    "    if total_seen % 1000 == 0:\n",
    "        print(\"Accuracy after %i images: %f\" %\n",
    "              (total_seen, float(num_correct) / float(total_seen)))\n",
    "\n",
    "  return float(num_correct) / float(total_seen)\n",
    "\n",
    "print(eval_model(interpreter, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zalu5Ng7D7xi"
   },
   "source": [
    "### 对 TensorFlow Lite模型的权重进行量化\n",
    "\n",
    "可以对模型的参数进行8位精确度的量化转换可将大小缩减至原来的1/4.但是准确度有所降低。\n",
    "原因：float为32位？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wbTNqf1KER0z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "INFO:tensorflow:Converted 12 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(pruned_keras_file)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "tflite_quant_model_file = './sparse_mnist_quant.tflite'\n",
    "with open(tflite_quant_model_file, 'wb') as f:\n",
    "  f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6a8bH_-EXeR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the tflite model before compression: 3.13 Mb\n",
      "Size of the tflite model after compression: 0.59 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_tflite = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(tflite_quant_model_file)\n",
    "print(\"Size of the tflite model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(tflite_quant_model_file) / float(2**20)))\n",
    "print(\"Size of the tflite model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip_tflite) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMuuxZs_QxMt"
   },
   "source": [
    "The size of the quantized model is roughly 1/4 of the orignial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dkv9mauCEami"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 1000 images: 0.991000\n",
      "Accuracy after 2000 images: 0.990000\n",
      "Accuracy after 3000 images: 0.986667\n",
      "Accuracy after 4000 images: 0.988500\n",
      "Accuracy after 5000 images: 0.988400\n",
      "Accuracy after 6000 images: 0.990000\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_quant_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "print(eval_model(interpreter, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygzK3KZcoZ-w"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we showed you how to create *sparse models* with the TensorFlow model optimization toolkit weight pruning API. Right now, this allows you to create models that take significant less space on disk. The resulting model can also be more efficiently implemented to avoid computation; in the future TensorFlow Lite will provide such capabilities.\n",
    "\n",
    "More specifically, we walked you through an end-to-end example of training a simple MNIST model that used the weight pruning API. We showed you how to convert it to the Tensorflow Lite format for mobile deployment, and demonstrated how with simple file compression the model size was reduced 5x.\n",
    "\n",
    "We encourage you to try this new capability on your Keras models, which can be particularly important for deployment in resource-constraint environments. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "JCkPHee-alKM"
   ],
   "name": "pruning_with_keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
